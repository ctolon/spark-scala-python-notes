{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f550700",
   "metadata": {},
   "source": [
    "# Sorular\n",
    "\n",
    "1. SparkContext sınıfını kullanarak local modda çalışan 2 çekirdek, 2 Gb. driver, 3 Gb executor belleğine sahip, \"Test\" isimli ekrana \"Merhaba Spark\" yazan bir Spark uygulaması yazınız.\n",
    "\n",
    "2. 3,7,13,15,22,36,7,11,3,25 rakamlarından bir RDD oluşturunuz.\n",
    "\n",
    "3. \"Spark'ı öğrenmek çok heyecan verici\" cümlesinin tüm harflerini büyük harf yapınız.\n",
    "\n",
    "4. https://github.com/veribilimiokulu/udemy-apache-spark/blob/master/docs/Ubuntu_Spark_Kurulumu.txt adresindeki text dosyasını Spark ile okuyarak kaç satırdan oluştuğunu ekrana yazdırınız.\n",
    "\n",
    "5. https://github.com/veribilimiokulu/udemy-apache-spark/blob/master/docs/Ubuntu_Spark_Kurulumu.txt adresindeki text dosyasını Spark ile okuyarak kaç kelimeden oluştuğunu ekrana yazdırınız. (Kelimeler tekrarlanabilir)\n",
    "\n",
    "6. İkinci sorudaki rakam listesi ile 1,2,3,4,5,6,7,8,9,10 listesi arasındaki kesişim kümesini(ortak rakamları) Spark uygulaması ile ekrana yazdırınız.\n",
    "\n",
    "7. İkinci sorudaki rakamların tekil (rakamların tekrarlanmaması) halinden oluşan bir RDD yaratınız.\n",
    "\n",
    "8. İkinci sorudaki rakamların liste içinde kaçar kez tekrarlandıklarını (frekanslarını) bulan bir Spark uygulaması yazınız."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d13d3e",
   "metadata": {},
   "source": [
    "### Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9635125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merhaba Spark\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "pyspark = SparkSession.builder \\\n",
    ".master(\"local[2]\") \\\n",
    ".appName(\"Test\") \\\n",
    ".config(\"spark.executor.memory\", \"3g\") \\\n",
    ".config(\"spark.driver.memory\", \"2g\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "sc = pyspark.sparkContext\n",
    "\n",
    "print(\"Merhaba Spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2c3455",
   "metadata": {},
   "source": [
    "### Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d48c25c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 7, 13, 15, 22, 36, 7, 11, 3, 25]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [3,7,13,15,22,36,7,11,3,25]\n",
    "rdd_1 = sc.parallelize(data)\n",
    "rdd_1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce73987",
   "metadata": {},
   "source": [
    "### Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09d96e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SPARK'I ÖĞRENMEK ÇOK HEYECAN VERICI\"]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Spark'ı öğrenmek çok heyecan verici\"\n",
    "rdd_sentence = sc.parallelize([sentence])\n",
    "upper_sentence = rdd_sentence.map(lambda x: x.upper())\n",
    "print(upper_sentence.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9793be2",
   "metadata": {},
   "source": [
    "### Question 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb691114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "spark_install_txt = \"Ubuntu_Spark_Kurulumu.txt\"\n",
    "full_path = f\"{CURRENT_PATH}/{spark_install_txt}\"\n",
    "load_file_rdd = sc.textFile(full_path)\n",
    "n_lines = load_file_rdd.flatMap(lambda line: line.split(\"\\n\"))\n",
    "n_lines.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77967a86",
   "metadata": {},
   "source": [
    "### Question 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "673430b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 1, 1, 2, 1, 3, 6, 1, 1, 3, 1, 6, 3, 2, 2, 1, 2, 1, 3, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 3, 1, 2, 5, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 22, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "spark_install_txt = \"Ubuntu_Spark_Kurulumu.txt\"\n",
    "full_path = f\"{CURRENT_PATH}/{spark_install_txt}\"\n",
    "load_file_rdd = sc.textFile(full_path)\n",
    "n_words = load_file_rdd.flatMap(lambda line: line.split(\" \"))\n",
    "words_numbers = n_words.map(lambda word: (word, 1))\n",
    "reduced_words = words_numbers.reduceByKey(lambda x,y: x+y)\n",
    "reversed_words = reduced_words.map(lambda x: (x[1], x[0]))\n",
    "total_keys = reversed_words.keys()\n",
    "print(total_keys.collect())\n",
    "total_keys.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429c404",
   "metadata": {},
   "source": [
    "### Question 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "414163dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 7]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = [1,2,3,4,5,6,7,8,9,10]\n",
    "rdd_2 = sc.parallelize(data_2)\n",
    "intersected = rdd_1.intersection(rdd_2)\n",
    "intersected.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4969d",
   "metadata": {},
   "source": [
    "### Question 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce27a983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 36, 22, 7, 25, 11, 13, 15]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_nums_rdd = rdd_1.distinct()\n",
    "unique_nums_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69fd2c3",
   "metadata": {},
   "source": [
    "### Question 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "442d99e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {3: 2, 7: 2, 13: 1, 15: 1, 22: 1, 36: 1, 11: 1, 25: 1})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = rdd_1.countByValue()\n",
    "duplicates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
